{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/nbformat/__init__.py:96: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Great British Bake Off (A/B Test)\n",
    "\n",
    "Welcome to Data 8 Lab 7! This week's lab will focus on A/B Testing using data from the ever-popular British television show, [*The Great British Bake Off*](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off).\n",
    "\n",
    "#### **Helpful Resource:**\n",
    "- [Python Reference](http://data8.org/su24/reference/)\n",
    "\n",
    "**Recommended Readings:**\n",
    "\n",
    "* [Error Probabilities](https://inferentialthinking.com/chapters/11/4/Error_Probabilities.html)\n",
    "* [A/B Testing](https://inferentialthinking.com/chapters/12/1/AB_Testing.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "#warnings.simplefilter('ignore', (FutureWarning, np.VisibleDeprecationWarning))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Great British Bake Off\n",
    "\n",
    ">\"The Great British Bake Off (often abbreviated to Bake Off or GBBO) is a British television baking competition, produced by Love Productions, in which a group of amateur bakers compete against each other in a series of rounds, attempting to impress a group of judges with their baking skills\" [Wikipedia](https://en.wikipedia.org/wiki/The_Great_British_Bake_Off)\n",
    "\n",
    "For every week of the competition, the judges assign one contestant the title \"Star Baker\". Ultimately, one winner is crowned every season. Using this information, we would like to investigate how winning Star Baker awards affects the odds of winning a season of the show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an Experiment\n",
    "\n",
    "We are going to run the following hypothesis test to determine the association between winning and number of Star Baker awards. The population we are examining is every contestant from seasons 2 through 11 of GBBO. We are going to use the following null and alternative hypotheses:\n",
    "\n",
    "**Null hypothesis:** The distribution of Star Baker awards between contestants who won their season and contestants who did not win their season is the same.\n",
    "\n",
    "**Alternative hypothesis:** Contestants who win their season of the show will win more Star Baker awards on average.\n",
    "\n",
    "Our alternative hypothesis is related to our suspicion that contestants who win more Star Baker awards are more skilled, so they are more likely to win the season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bakers` table below describes the number of star baker awards each contest won and whether or not they won their season (`1` if they won, `0` if they did not win). The data was manually aggregated from Wikipedia for seasons 2-11 of the show. We randomized the order of rows as to not spoil the outcome of the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>star baker awards</th> <th>won</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>3                </td> <td>1   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0                </td> <td>0   </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1                </td> <td>0   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (119 rows omitted)</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bakers = Table.read_table(\"star_bakers.csv\")\n",
    "bakers.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Create a new table called `means` that contains the mean number of star baker awards for bakers who did not win (`won==0`) and bakers that did win (`won==1`). The table should have the column names `won` and `star baker awards mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>won</th> <th>star baker awards mean</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0   </td> <td>0.651786              </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>1   </td> <td>1.5                   </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "won  | star baker awards mean\n",
       "0    | 0.651786\n",
       "1    | 1.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = bakers.group(\"won\",np.mean)\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Visualize the distribution of Star Baker awards for winners and non-winners as overlaid histograms. You should use the bins we provided.\n",
    "\n",
    "Hint: You will want to use the group argument of `tbl.hist`. In order to produce several overlayed histograms based on unique values in a given column, we can do something like `tbl.hist(..., group=<col_name>, bins=...)`. This will graph one histogram for each unique value in the specified column all on a single plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "useful_bins = np.arange(0, 7)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** We want to figure out if there is a difference between the distribution of Star Baker awards between winners and non winners. \n",
    "\n",
    "What should the test statistic be? Which values of this test statistic support the null, and which values support the alternative? **Assign `test_option` to the number corresponding to the correct test statistic.**\n",
    "\n",
    "1. Absolute value of the difference between the means between both groups; high values support the null\n",
    "2. Absolute value of the difference between the means between both groups; low values support the null\n",
    "3. Average Star Baker awards for winners - average Star Baker awards for non-winners; high values support the null\n",
    "4. Average Star Baker awards for winners - average Star Baker awards for non-winners; low values support the null\n",
    "\n",
    "_Hint:_ You should think about what measures we use to describe a distribution. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_option = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Set `observed_difference` to the observed test statistic using the `means` table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "observed_difference = ...\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7.** Given a table like `bakers`, a label column `label_col`, and a values column `val_col`, write a function that calculates the appropriate test statistic.\n",
    "\n",
    "*Hint:* Make sure that you are taking the directionality of our alternative hypothesis into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_test_stat(tbl, label_col, val_col):\n",
    "    ...\n",
    "\n",
    "find_test_stat(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run a simulation for A/B testing, we resample by **shuffling the labels** of the original sample. If the null hypothesis is true and the star baker award distributions are the same, we expect that the difference in mean star baker awards to not change when `\"won\"` labels are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8.** Write a function `simulate_and_test_statistic` to compute one trial of our A/B test. Your function should run a simulation and return a test statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def simulate_and_test_statistic(tbl, labels_col, values_col):\n",
    "    ...\n",
    "\n",
    "simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9.** Simulate 5000 trials of our A/B test and store the test statistics in an array called `differences`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell might take a couple seconds to run\n",
    "differences = make_array()\n",
    "\n",
    "...\n",
    "                                                 \n",
    "differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to view a histogram of your simulated test statistics plotted with your observed test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column('Difference Between Group Means', differences).hist(bins=20)\n",
    "plots.scatter(observed_difference, 0, color='red', s=30, zorder=2)\n",
    "plots.ylim(-0.1, 1.35);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10.** Find the p-value for your test and assign it to `empirical_p`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empirical_p = ...\n",
    "empirical_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11.** Using a 5% P-value cutoff, draw a conclusion about the null and alternative hypotheses. Describe your findings using simple, non-technical language. What does your analysis tell you about the association between star baker awards and winning? What can you claim about causation from your statistical analysis? Confirm your answer with a peer, instructor or in the discussion forums. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> mid_secret == \"hollow purple\"\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_1": {
     "name": "q1_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(ab_test_order) == 6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(np.array(ab_test_order)[:3] % 2 == 1, True) # Check the first three elements in your array.\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.allclose(np.array(ab_test_order)[3:] % 2 == 0, True) # Check the last three elements in your array.\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> \n>>> # This imports a hashing library for the autograder.\n>>> import hashlib\n>>> def get_hash(num):\n...     \"\"\"Helper function for assessing correctness.\"\"\"\n...     return hashlib.md5(str(num).encode()).hexdigest()\n>>> \n>>> get_hash(np.array(ab_test_order).astype(int))\n'a7196ed0f271c873d9750cb92422d911'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_10": {
     "name": "q2_10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= empirical_p < 0.05\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_3": {
     "name": "q2_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> means.num_rows\n2",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.round(min(means.column(\"star baker awards mean\")), 2) == 0.65\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.round(max(means.column(\"star baker awards mean\")), 2) == 1.5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_5": {
     "name": "q2_5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_option == 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_6": {
     "name": "q2_6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(observed_difference, float)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> float(round(observed_difference, 3))\n0.848",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_7": {
     "name": "q2_7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(round(find_test_stat(bakers, \"won\", \"star baker awards\"), 3) - 0.848, 0)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_8": {
     "name": "q2_8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> test_stat = round(simulate_and_test_statistic(bakers, \"won\", \"star baker awards\"), 3)\n>>> -2 < test_stat < 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.random.seed(1)\n>>> test_stat2 = simulate_and_test_statistic(bakers, \"won\", \"star baker awards\")\n>>> np.round(test_stat2, 3) == -0.023 or np.round(test_stat2, 3) == -0.132\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_9": {
     "name": "q2_9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(differences)\n5000",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> abs(np.average(differences)) < 0.05 # On average, your test statistic should be close to 0\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(differences == differences.item(0)) == False # Make sure all of the test statistics are different\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
