{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/nbformat/__init__.py:96: MissingIDFieldWarning: Cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw07.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Testing Hypotheses\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the previous cell to load the provided tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helpful Resource:**\n",
    "\n",
    "- [Python Reference](http://data8.org/su24/reference/): Cheat sheet of helpful array & table methods used in Data 8!\n",
    "\n",
    "**Recommended Readings**: \n",
    "\n",
    "* [Sampling Methods Guide](https://drive.google.com/file/d/1UtNdxDdI5XphWvwgTjODiAUFwArpZtoK/view)\n",
    "* [Testing Hypotheses](https://www.inferentialthinking.com/chapters/11/Testing_Hypotheses.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "\n",
    "# These lines import the Numpy and Datascience modules.\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vaccinations Across The Nation\n",
    "\n",
    "A vaccination clinic has two types of vaccines against a disease. Each person who comes in to be vaccinated gets either Vaccine 1 or Vaccine 2. One week, everyone who came in on Monday, Wednesday, and Friday was given Vaccine 1. Everyone who came in on Tuesday and Thursday was given Vaccine 2. The clinic is closed on weekends.\n",
    "\n",
    "Doctor DeNero at the clinic said, \"Oh wow, the distribution of vaccines is like tossing a coin that lands heads with probability $\\frac{3}{5}$. If the coin lands on heads, you get Vaccine 1 and if the coin lands on tails, you get Vaccine 2.\"\n",
    "\n",
    "But Doctor Sahai said, \"No, it's not. We're not doing anything like tossing a (biased) coin.\"\n",
    "\n",
    "That week, the clinic gave Vaccine 1 to 211 people and Vaccine 2 to 107 people. Conduct a test of hypotheses to see which doctor's position is better supported by the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Given the information above, what was the sample size for the data, and what was the percentage of people who got **Vaccine 1?**\n",
    "\n",
    "*Note*: Your percent should be a number between 0 and 100, not a proportion between 0 and 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 318\n",
      "Vaccine 1 Percent: 66.35220125786164\n"
     ]
    }
   ],
   "source": [
    "sample_size = 318\n",
    "percent_V1 = 211/sample_size *100\n",
    "\n",
    "print(f\"Sample Size: {sample_size}\")\n",
    "print(f\"Vaccine 1 Percent: {percent_V1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_1</pre></strong> passed! ðŸš€</p>"
      ],
      "text/plain": [
       "q1_1 results: All test cases passed!"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.2.** State the null hypothesis. It should reflect the position of either Dr. DeNero or Dr. Sahai.\n",
    "\n",
    "*Note:* Check out [11.3](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html#step-1-the-hypotheses) for a refresher on hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data is generated on a biased coin 3/5 in head favor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.3.** State the alternative hypothesis. It should reflect the position of the doctor you did not choose to represent in Question 1.2.\n",
    "\n",
    "*Note:* Check out [11.3](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html#step-1-the-hypotheses) for a refresher on hypotheses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that data is not generated by a random coin flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.4.** One of the test statistics below is appropriate for testing these hypotheses. Assign the variable `valid_test_stat` to the number corresponding to the correct test statistic.\n",
    "\n",
    "_Hint:_ Recall that large values of the test statistic should favor the alternative hypothesis.\n",
    "\n",
    "1. percent of heads - 60\n",
    "2. |percent of heads - 60|\n",
    "3. percent of heads - 50\n",
    "4. |percent of heads - 50|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_test_stat = 2\n",
    "valid_test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_4</pre></strong> passed! âœ¨</p>"
      ],
      "text/plain": [
       "q1_4 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Using your answer from Questions 1.1 and 1.4, find the observed value of the test statistic and assign it to the variable `observed_statistic`. Recall that the observed statistic is the test statistic value that was observed in the real life data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.352201257861637"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_statistic = abs(percent_V1-60)\n",
    "observed_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_5</pre></strong> passed! ðŸ’¯</p>"
      ],
      "text/plain": [
       "q1_5 results: All test cases passed!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6.** In order to perform this hypothesis test, you must simulate the test statistic. From the four options below, pick the assumption that is needed for this simulation. Assign `assumption_needed` to an integer corresponding to the assumption.\n",
    "\n",
    "1. The statistic must be simulated under the null hypothesis.\n",
    "2. The statistic must be simulated under the alternative hypothesis.\n",
    "3. The statistic must be simulated under both hypotheses.\n",
    "4. No assumptions are needed. We can just simulate the statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assumption_needed = 1\n",
    "assumption_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1_6</pre></strong> passed! âœ¨</p>"
      ],
      "text/plain": [
       "q1_6 results: All test cases passed!"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 1.7.** Simulate 20,000 values of the test statistic under the assumption you picked in Question 1.6.\n",
    "\n",
    "As usual, start by defining a function that simulates one value of the statistic. Your function should use `sample_proportions`. (You may find a variable defined in Question 1.1 useful here!) Then, write a `for` loop to simulate multiple values and collect them in the array `simulated_statistics`.\n",
    "\n",
    "Use as many lines of code as you need. We have included the code that visualizes the distribution of the simulated values. The red dot represents the observed statistic you found in Question 1.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_simulated_statistic():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the this cell a few times to see how the simulated statistic changes\n",
    "one_simulated_statistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to ellipsis (3633248600.py, line 4)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor ... in ...:\u001b[39m\n        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m cannot assign to ellipsis\n"
     ]
    }
   ],
   "source": [
    "num_simulations = 20000\n",
    "\n",
    "simulated_statistics = ...\n",
    "for ... in ...:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to produce a histogram of the simulated statistics\n",
    "\n",
    "Table().with_columns('Simulated Statistic', simulated_statistics).hist()\n",
    "plt.scatter(observed_statistic, -0.002, color='red', s=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.8.** Using `simulated_statistics`, `observed_statistic`, and `num_simulations`, find the empirical p-value based on the simulation.\n",
    "\n",
    "_Hint:_ Reading [11.3.6](https://inferentialthinking.com/chapters/11/3/Decisions_and_Uncertainty.html#the-meaning-of-consistent) might be helpful for this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9.** Assign `correct_doctor` to the number corresponding to the correct statement below. Use the 5% cutoff for the p-value.\n",
    "\n",
    "1. The data support Dr. DeNero's position more than they support Dr. Sahai's.\n",
    "2. The data support Dr. Sahai's position more than they support Dr. DeNero's.\n",
    "\n",
    "As a reminder, here are the two claims made by Dr. DeNero and Dr. Sahai:\n",
    "> **Doctor DeNero:** \"Oh wow, it's just like tossing a coin that lands heads with chance $\\frac{3}{5}$. Heads you get Vaccine 1 and Tails you get Vaccine 2.\"\n",
    "\n",
    ">**Doctor Sahai:** \"No, it's not. We're not doing anything like tossing a coin.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_doctor = ...\n",
    "correct_doctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using TVD as a Test Statistic\n",
    "\n",
    "Before beginning this section, please read [this section](https://inferentialthinking.com/chapters/11/2/Multiple_Categories.html#a-new-statistic-the-distance-between-two-distributions) of the textbook on TVD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total variation distance (TVD)** is a special type of test statistic that we use when we want to compare two distributions of *categorical data*. It is often used when we observe that a set of observed proportions/probabilities is different than what we expect under the null model. \n",
    "\n",
    "Consider a six-sided die that we roll 6,000 times. If the die is fair, we would expect that each face comes up $\\frac{1}{6}$ of the time. By random chance, a fair die won't always result in equal proportions (that is, we won't get exactly 1,000 of each face). However, if we suspect that the die might be unfair based on the data, we can conduct a hypothesis test using TVD to compare the expected [$\\frac{1}{6}$, $\\frac{1}{6}$, $\\frac{1}{6}$, $\\frac{1}{6}$, $\\frac{1}{6}$, $\\frac{1}{6}$] distribution to what is actually observed.\n",
    "\n",
    "In this part of the homework, we'll look at how we can use TVD to determine the effect that different factors have on happiness. \n",
    "\n",
    "We will be working with data from the [Gallup World Poll](https://worldhappiness.report/ed/2023/world-happiness-trust-and-social-connections-in-times-of-crisis/#ranking-of-happiness-2020-2022) that is presented in the World Happiness Report, a survey of the state of global happiness. The survey ranked 137 countries by overall happiness and estimated the influence that economic production, social support, life expectancy, freedom, absence of corruption, and generosity had on population happiness. The study has been repeated for several years, but we'll be looking at data from the 2023 survey.\n",
    "\n",
    "Run the cell below to load in the `happiness_scores` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happiness_scores = Table.read_table(\"happiness_scores.csv\").drop(12, 13, 14).take(np.arange(137))\n",
    "happiness_scores.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Participants in the study were asked to evaluate their life satisfaction from a scale of 0 (worst possible life) to 10 (best possible life). The responses for each country were averaged to create the `Happiness Score`.\n",
    "\n",
    "The columns `Economy (Log GDP per Capita)`, `Family`, `Health (Life Expectancy)`, `Freedom`, `Generosity`, and `Trust (Government Corruption)` estimate the extent to which each factor influences happiness, both for better or for worse. The happiness score is the sum of these factors; the larger a factor is, the more it contributes to overall happiness. [In other words, if you add up all the factors (in addition to a \"Difference from Dystopia\" value we excluded in the dataset), you get the happiness score.]\n",
    "\n",
    "Let's look at the different factors that affect happiness in the United States. Run the cell below to view the row in `us_happiness` that contains data for the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_happiness = happiness_scores.where(\"Country\", \"United States\")\n",
    "us_happiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To compare the different factors, we'll look at the proportion of the happiness score that is attributed to each variable. \n",
    "You can find these proportions in the table `us_happiness_factors` after running the cell below.**\n",
    "\n",
    "*Note:* The factors shown in `us_happiness` don't add up exactly to the happiness score, so we adjusted the proportions to  only account for the data we have access to. The proportions were found by dividing each Happiness Factor value by the sum of all Happiness Factor values in `us_happiness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_happiness_factors = Table().read_table(\"us_happiness_factors.csv\")\n",
    "us_happiness_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.1.** Suppose we want to test whether or not each factor contributes the same amount to the overall Happiness Score. Define the null hypothesis, alternative hypothesis, and test statistic in the cell below.\n",
    "\n",
    "*Note:* Please format your answer as follows:\n",
    "- Null Hypothesis: ...  \n",
    "- Alternative Hypothesis: ...  \n",
    "- Test Statistic: ...  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.2.** Write a function `calculate_tvd` that takes in the observed distribution (`obs_dist`) and expected distribution under the null hypothesis (`null_dist`) and calculates the total variation distance. Use this function to set `observed_tvd` to be equal to the observed test statistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_distribution = make_array(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)\n",
    "\n",
    "def calculate_tvd(obs_dist, null_dist):\n",
    "    ...\n",
    "    \n",
    "observed_tvd = ...\n",
    "observed_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Create an array called `simulated_tvds` that contains 10,000 simulated values under the null hypothesis. Assume that the original sample consisted of 1,000 individuals.\n",
    "\n",
    "*Hint:* The `sample_proportions` function may be helpful to you. Refer to the [Python Reference Sheet](http://data8.org/su24/reference/) to read up on it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simulated_tvds = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to plot a histogram of your simulated test statistics, as well as a red dot representing the observed value of the test statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Table().with_column(\"Simulated TVDs\", simulated_tvds).hist()\n",
    "plt.scatter(observed_tvd, 0.5, color='red', s=70, zorder=2);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Use your simulated statistics to calculate the p-value of your test. Make sure that this number is consistent with what you observed in the histogram above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p_value_tvd = ...\n",
    "p_value_tvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 2.5.** What can you conclude about how each factor contributes to the overall happiness score in the US? Explain your answer using the results of your hypothesis test. Assume a p-value cutoff of 5%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": [
      0,
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(sample_size) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(percent_V1) == float or type(percent_V1) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 100 <= sample_size <= 500\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 1 <= percent_V1 <= 100\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_4": {
     "name": "q1_4",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(valid_test_stat) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any((valid_test_stat == x for x in np.arange(1,5)))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_5": {
     "name": "q1_5",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(observed_statistic) == float\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= observed_statistic <= 100\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_6": {
     "name": "q1_6",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(assumption_needed) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 1 <= assumption_needed <= 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_8": {
     "name": "q1_8",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> type(p_value) == float or type(p_value) == np.float64\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= p_value <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_9": {
     "name": "q1_9",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(correct_doctor) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any((correct_doctor == x for x in (1,2)))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": [
      2,
      2
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(observed_tvd) in set([float, np.float32, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(round(observed_tvd, 6), 0.38791256)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_3": {
     "name": "q2_3",
     "points": [
      1,
      1,
      1,
      1
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(simulated_tvds) == 10000\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(simulated_tvds >= 0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Make sure that your test statistic is not always the same value \n>>> len(np.unique(simulated_tvds)) != 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Make sure you're simulating under the null hypothesis\n>>> np.mean(simulated_tvds) < 0.1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_4": {
     "name": "q2_4",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= p_value_tvd <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> 0 <= num_females <= 500\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_10": {
     "name": "q3_10",
     "points": [],
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_11": {
     "name": "q3_11",
     "points": [
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(p_val) in set([float, np.float32, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 0 <= p_val <= 1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(conclusion) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_2": {
     "name": "q3_2",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> import numpy as np\n>>> type(avg_male_vs_female) in set([bool, np.bool_])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_3": {
     "name": "q3_3",
     "points": [
      0,
      0,
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(null_statement_number) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(alternative_statement_number) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any(null_statement_number == x for x in np.arange(1,7))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any(alternative_statement_number == x for x in np.arange(1,7))\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> null_statement_number != alternative_statement_number\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_4": {
     "name": "q3_4",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(permutation_test_reason) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any(permutation_test_reason == x for x in np.arange(1,4))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_5": {
     "name": "q3_5",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(correct_test_stat) == int\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> any(correct_test_stat == x for x in np.arange(1,3))\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_6": {
     "name": "q3_6",
     "points": [
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(observed_statistic_ab) in set([float, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> observed_statistic_ab >= 0\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_7": {
     "name": "q3_7",
     "points": [
      0,
      0,
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(original_with_shuffled_labels) == Table\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> original_with_shuffled_labels.labels == (\"Gender\", \"Age\", \"Shuffled Label\")\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> original_with_shuffled_labels.num_rows == 500\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_8": {
     "name": "q3_8",
     "points": [
      0
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(correct_q8) == str\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_9": {
     "name": "q3_9",
     "points": [
      4
     ],
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -5 < simulate_one_statistic() < 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
